{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sna_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMotD16Vlb18Z9xNViFIQeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asto7/deep-learning/blob/main/sna_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nrohani/NDD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PS2L04W7Jqo",
        "outputId": "7bc0f9a7-6437-4756-af32-9d73b1bee632"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NDD'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 104 (delta 19), reused 44 (delta 19), pack-reused 60\u001b[K\n",
            "Receiving objects: 100% (104/104), 18.62 MiB | 19.48 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xiTqYy-9Jno",
        "outputId": "40efda49-0e37-43d0-a2f8-cf32394ed4d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 160 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python NDD/NDD/DS1/MainExample.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfmrRfuZ9Pa_",
        "outputId": "1e78cd76-1d61-47af-e562-0f3bba23c25a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 2633072640 bytes == 0x69482000 @  0x7f050676e1e7 0x7f050407f0ce 0x7f05040db715 0x7f05040dbd1b 0x7f050417c333 0x5936cc 0x548c51 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e 0x593fce 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f050636bc87 0x5b621a\n",
            "tcmalloc: large alloc 1316536320 bytes == 0x106ba6000 @  0x7f050676e1e7 0x7f050407f0ce 0x7f05040db715 0x7f05040dbd1b 0x7f050417c333 0x5936cc 0x548c51 0x51566f 0x593dd7 0x5118f8 0x549e0e 0x593fce 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f050636bc87 0x5b621a\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "tcmalloc: large alloc 2633072640 bytes == 0x69482000 @  0x7f050676e1e7 0x7f050407f0ce 0x7f05040d5cf5 0x7f050417e86d 0x7f050417f17f 0x7f050417f2d0 0x4bc4ab 0x7f05040c0944 0x59371f 0x515244 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e 0x593fce 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f050636bc87 0x5b621a\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "import matplotlib\n",
        "from keras.layers.core import Dropout, Activation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "#--------------------------------------------------\n",
        "#NDD Methods\n",
        "def prepare_data(seperate=False):\n",
        "    drug_fea = np.loadtxt(\"./NDD/NDD/DS1/IntegratedDS1.txt\",dtype=float,delimiter=\",\")\n",
        "    interaction = np.loadtxt(\"./NDD/NDD/DS1/drug_drug_matrix.csv\",dtype=int,delimiter=\",\")\n",
        "    train = []\n",
        "    label = []\n",
        "    tmp_fea=[]\n",
        "    drug_fea_tmp = []\n",
        "    for i in range(0, interaction.shape[0]):\n",
        "        for j in range(0, interaction.shape[1]):\n",
        "            label.append(interaction[i,j])\n",
        "            drug_fea_tmp = list(drug_fea[i])\n",
        "            if seperate:\n",
        "        \n",
        "                 tmp_fea = (drug_fea_tmp,drug_fea_tmp)\n",
        "\n",
        "            else:\n",
        "                 tmp_fea = drug_fea_tmp + drug_fea_tmp\n",
        "            train.append(tmp_fea)\n",
        "\n",
        "    return np.array(train), label\n",
        "#--------------------------------------------------------------\n",
        "def calculate_performace(test_num, pred_y,  labels):\n",
        "    tp =0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for index in range(test_num):\n",
        "        if labels[index] ==1:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tp = tp +1\n",
        "            else:\n",
        "                fn = fn + 1\n",
        "        else:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tn = tn +1\n",
        "            else:\n",
        "                fp = fp + 1 \n",
        "    acc = float(tp + tn)/test_num\n",
        "    if tp == 0 and fp == 0:\n",
        "        precision = 0\n",
        "        MCC = 0\n",
        "        sensitivity = float(tp)/ (tp+fn)\n",
        "        specificity = float(tn)/(tn + fp)\n",
        "    else:\n",
        "        precision = float(tp)/(tp+ fp)\n",
        "        sensitivity = float(tp)/ (tp+fn)\n",
        "        specificity = float(tn)/(tn + fp)\n",
        "        MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
        "    return acc, precision, sensitivity, specificity, MCC \n",
        "#-----------------------------------------------------\n",
        "def transfer_array_format(data):\n",
        "    formated_matrix1 = []\n",
        "    formated_matrix2 = []\n",
        "    for val in data:\n",
        "        formated_matrix1.append(val[0])\n",
        "        formated_matrix2.append(val[1])\n",
        "    return np.array(formated_matrix1), np.array(formated_matrix2)\n",
        "#-------------------------------------------------------\n",
        "def preprocess_labels(labels, encoder=None, categorical=True):\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "        y = encoder.transform(labels).astype(np.int32)\n",
        "    if categorical:\n",
        "        y = np_utils.to_categorical(y)\n",
        "        print(y)\n",
        "    return y, encoder\n",
        "#------------------------------------------------------\n",
        "def preprocess_names(labels, encoder=None, categorical=True):\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "    if categorical:\n",
        "        labels = np_utils.to_categorical(labels)\n",
        "    return labels, encoder\n",
        "#------------------------------------------------------\n",
        "def NDD(input_dim): \n",
        "    model = Sequential()\n",
        "    model.add(Dense(input_dim=input_dim, output_dim=400,init='glorot_normal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(input_dim=400, output_dim=300,init='glorot_normal'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(input_dim=300, output_dim=2,init='glorot_normal'))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd)                  \n",
        "    return model\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------\n",
        "def DeepMDA():\n",
        "    X, labels = prepare_data(seperate = True)\n",
        "    X_data1, X_data2 = transfer_array_format(X) \n",
        "    X=0\n",
        "    y, encoder = preprocess_labels(labels)# labels labels_new\n",
        "    X= np.concatenate((X_data1, X_data2), axis = 1)\n",
        "    num = np.arange(len(y))\n",
        "    np.random.shuffle(num)\n",
        "    X_data1 = X_data1[num]\n",
        "    X_data2 = X_data2[num]\n",
        "    y = y[num]\n",
        "    num_cross_val = 5\n",
        "    all_performance_DNN = []\n",
        "    for fold in range(num_cross_val):\n",
        "        train_label = np.array([x for i, x in enumerate(y) if i % num_cross_val != fold])\n",
        "        test_label = np.array([x for i, x in enumerate(y) if i % num_cross_val == fold])\n",
        "        train1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val != fold])\n",
        "        test1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val == fold])\n",
        "        train2 = np.array([x for i, x in enumerate(X_data2) if i % num_cross_val != fold])\n",
        "        test2 = np.array([x for i, x in enumerate(X_data2) if i % num_cross_val == fold])\n",
        "     \n",
        "        zerotest=0\n",
        "        nozerotest=0\n",
        "        zerotrain=0\n",
        "        nozerotrain=0\n",
        "        real_labels = []\n",
        "        for val in test_label:\n",
        "            if val[0] == 1:\n",
        "                nozerotest=nozerotest+1\n",
        "                real_labels.append(1)\n",
        "            else:\n",
        "                zerotest=zerotest+1\n",
        "                real_labels.append(0)\n",
        "        train_label_new = []\n",
        "        for val in train_label:\n",
        "            if val[0] == 1:\n",
        "                zerotrain=zerotrain+1\n",
        "                train_label_new.append(1)\n",
        "            else:\n",
        "                nozerotrain=nozerotrain+1\n",
        "                train_label_new.append(0)\n",
        "       \n",
        "        prefilter_train = np.concatenate((train1, train2), axis = 1)\n",
        "        prefilter_test = np.concatenate((test1, test2), axis = 1)\n",
        "        \n",
        "        model_DNN = NDD(prefilter_train.shape[1])\n",
        "        train_label_new_forDNN = np.array([[0,1] if i == 1 else [1,0] for i in train_label_new])\n",
        "\n",
        "        model_DNN.fit(prefilter_train,train_label_new_forDNN,batch_size=100,epochs=20,shuffle=True,validation_split=0)\n",
        "        proba = model_DNN.predict_classes(prefilter_test,batch_size=200,verbose=True)\n",
        "        ae_y_pred_prob = model_DNN.predict_proba(prefilter_test,batch_size=200,verbose=True)\n",
        "        acc, precision, sensitivity, specificity, MCC = calculate_performace(len(real_labels), proba,  real_labels)\n",
        "        fpr, tpr, auc_thresholds = roc_curve(real_labels, ae_y_pred_prob[:,1])\n",
        "        auc_score = auc(fpr, tpr)\n",
        "        precision1, recall, pr_threshods = precision_recall_curve(real_labels, ae_y_pred_prob[:,1])\n",
        "        aupr_score = auc(recall, precision1)\n",
        "        all_F_measure=np.zeros(len(pr_threshods))\n",
        "        for k in range(0,len(pr_threshods)):\n",
        "\n",
        "           if (precision1[k]+precision1[k])>0:\n",
        "              all_F_measure[k]=2*precision1[k]*recall[k]/(precision1[k]+recall[k])\n",
        "           else:\n",
        "              all_F_measure[k]=0\n",
        "\n",
        "        max_index=all_F_measure.argmax()\n",
        "        predicted_score=np.zeros(len(real_labels))\n",
        "        threshold=pr_threshods[max_index]\n",
        "        p=ae_y_pred_prob[:,1]\n",
        "        predicted_score[p>threshold]=1\n",
        "        f=f1_score(real_labels,predicted_score)\n",
        "        recall=recall_score(real_labels, predicted_score)\n",
        "        precision1=precision_score(real_labels, predicted_score)\n",
        "        print(\"RAW DNN:\",recall, precision1,'auc:', auc_score,'aupr', aupr_score,f)\n",
        "        all_performance_DNN.append([recall,precision1,auc_score,aupr_score,f])\n",
        "    print('recall,precision,auc_score,aupr_score,fscore')\n",
        "    print(np.mean(np.array(all_performance_DNN), axis=0))\n",
        "\n",
        "DeepMDA()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adxi9yF59VQj",
        "outputId": "0d369019-e398-495e-96ae-6df034a9a53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zCDhZ65K_9Cb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}