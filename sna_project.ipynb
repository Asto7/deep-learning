{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sna_project.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asto7/deep-learning/blob/main/sna_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nrohani/NDD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PS2L04W7Jqo",
        "outputId": "cf78f48d-09b1-4431-e52c-571380a5f55e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NDD'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 104 (delta 19), reused 44 (delta 19), pack-reused 60\u001b[K\n",
            "Receiving objects: 100% (104/104), 18.62 MiB | 12.52 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xiTqYy-9Jno",
        "outputId": "158738db-7907-44e8-d226-4fb7ab4c2b0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 160 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python NDD/NDD/DS1/MainExample.py"
      ],
      "metadata": {
        "id": "lfmrRfuZ9Pa_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "import matplotlib\n",
        "from keras.layers.core import Dropout, Activation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "#--------------------------------------------------\n",
        "#NDD Methods\n",
        "def prepare_data(seperate=False):\n",
        "    drug_fea = np.loadtxt(\"./NDD/NDD/DS1/IntegratedDS1.txt\",dtype=float,delimiter=\",\")\n",
        "    interaction = np.loadtxt(\"./NDD/NDD/DS1/drug_drug_matrix.csv\",dtype=int,delimiter=\",\")\n",
        "    train = []\n",
        "    label = []\n",
        "    tmp_fea=[]\n",
        "    drug_fea_tmp = []\n",
        "    for i in range(0, interaction.shape[0]):\n",
        "        for j in range(0, interaction.shape[1]):\n",
        "            label.append(interaction[i,j])\n",
        "            drug_fea_tmp = list(drug_fea[i])\n",
        "            if seperate:\n",
        "        \n",
        "                 tmp_fea = (drug_fea_tmp,drug_fea_tmp)\n",
        "\n",
        "            else:\n",
        "                 tmp_fea = drug_fea_tmp + drug_fea_tmp\n",
        "            train.append(tmp_fea)\n",
        "\n",
        "    return np.array(train), label\n",
        "#--------------------------------------------------------------\n",
        "def calculate_performace(test_num, pred_y,  labels):\n",
        "    tp =0\n",
        "    fp = 0\n",
        "    tn = 0\n",
        "    fn = 0\n",
        "    for index in range(test_num):\n",
        "        if labels[index] ==1:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tp = tp +1\n",
        "            else:\n",
        "                fn = fn + 1\n",
        "        else:\n",
        "            if labels[index] == pred_y[index]:\n",
        "                tn = tn +1\n",
        "            else:\n",
        "                fp = fp + 1 \n",
        "    acc = float(tp + tn)/test_num\n",
        "    if tp == 0 and fp == 0:\n",
        "        precision = 0\n",
        "        MCC = 0\n",
        "        sensitivity = float(tp)/ (tp+fn)\n",
        "        specificity = float(tn)/(tn + fp)\n",
        "    else:\n",
        "        precision = float(tp)/(tp+ fp)\n",
        "        sensitivity = float(tp)/ (tp+fn)\n",
        "        specificity = float(tn)/(tn + fp)\n",
        "        MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
        "    return acc, precision, sensitivity, specificity, MCC \n",
        "#-----------------------------------------------------\n",
        "def transfer_array_format(data):\n",
        "    formated_matrix1 = []\n",
        "    formated_matrix2 = []\n",
        "    for val in data:\n",
        "        formated_matrix1.append(val[0])\n",
        "        formated_matrix2.append(val[1])\n",
        "    return np.array(formated_matrix1), np.array(formated_matrix2)\n",
        "#-------------------------------------------------------\n",
        "def preprocess_labels(labels, encoder=None, categorical=True):\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "        y = encoder.transform(labels).astype(np.int32)\n",
        "    if categorical:\n",
        "        y = np_utils.to_categorical(y)\n",
        "        print(y)\n",
        "    return y, encoder\n",
        "#------------------------------------------------------\n",
        "def preprocess_names(labels, encoder=None, categorical=True):\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "    if categorical:\n",
        "        labels = np_utils.to_categorical(labels)\n",
        "    return labels, encoder\n",
        "#------------------------------------------------------\n",
        "def NDD(input_dim): \n",
        "    model = Sequential()\n",
        "    model.add(Dense(400, kernel_initializer='glorot_normal', input_dim=input_dim))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(300, kernel_initializer='glorot_normal', input_dim=400))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, kernel_initializer='glorot_normal', input_dim=300))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd)                  \n",
        "    return model\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------\n",
        "def DeepMDA():\n",
        "    X, labels = prepare_data(seperate = True)\n",
        "    X_data1, X_data2 = transfer_array_format(X) \n",
        "    X=0\n",
        "    y, encoder = preprocess_labels(labels)# labels labels_new\n",
        "    X= np.concatenate((X_data1, X_data2), axis = 1)\n",
        "    num = np.arange(len(y))\n",
        "    np.random.shuffle(num)\n",
        "    X_data1 = X_data1[num]\n",
        "    X_data2 = X_data2[num]\n",
        "    y = y[num]\n",
        "    num_cross_val = 5\n",
        "    all_performance_DNN = []\n",
        "    for fold in range(num_cross_val):\n",
        "        train_label = np.array([x for i, x in enumerate(y) if i % num_cross_val != fold])\n",
        "        test_label = np.array([x for i, x in enumerate(y) if i % num_cross_val == fold])\n",
        "        train1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val != fold])\n",
        "        test1 = np.array([x for i, x in enumerate(X_data1) if i % num_cross_val == fold])\n",
        "        train2 = np.array([x for i, x in enumerate(X_data2) if i % num_cross_val != fold])\n",
        "        test2 = np.array([x for i, x in enumerate(X_data2) if i % num_cross_val == fold])\n",
        "     \n",
        "        zerotest=0\n",
        "        nozerotest=0\n",
        "        zerotrain=0\n",
        "        nozerotrain=0\n",
        "        real_labels = []\n",
        "        for val in test_label:\n",
        "            if val[0] == 1:\n",
        "                nozerotest=nozerotest+1\n",
        "                real_labels.append(1)\n",
        "            else:\n",
        "                zerotest=zerotest+1\n",
        "                real_labels.append(0)\n",
        "        train_label_new = []\n",
        "        for val in train_label:\n",
        "            if val[0] == 1:\n",
        "                zerotrain=zerotrain+1\n",
        "                train_label_new.append(1)\n",
        "            else:\n",
        "                nozerotrain=nozerotrain+1\n",
        "                train_label_new.append(0)\n",
        "       \n",
        "        prefilter_train = np.concatenate((train1, train2), axis = 1)\n",
        "        prefilter_test = np.concatenate((test1, test2), axis = 1)\n",
        "        \n",
        "        model_DNN = NDD(prefilter_train.shape[1])\n",
        "        train_label_new_forDNN = np.array([[0,1] if i == 1 else [1,0] for i in train_label_new])\n",
        "\n",
        "        model_DNN.fit(prefilter_train,train_label_new_forDNN,batch_size=100,epochs=20,shuffle=True,validation_split=0)\n",
        "        proba = model_DNN.predict_classes(prefilter_test,batch_size=200,verbose=True)\n",
        "        ae_y_pred_prob = model_DNN.predict_proba(prefilter_test,batch_size=200,verbose=True)\n",
        "        acc, precision, sensitivity, specificity, MCC = calculate_performace(len(real_labels), proba,  real_labels)\n",
        "        fpr, tpr, auc_thresholds = roc_curve(real_labels, ae_y_pred_prob[:,1])\n",
        "        auc_score = auc(fpr, tpr)\n",
        "        precision1, recall, pr_threshods = precision_recall_curve(real_labels, ae_y_pred_prob[:,1])\n",
        "        aupr_score = auc(recall, precision1)\n",
        "        all_F_measure=np.zeros(len(pr_threshods))\n",
        "        for k in range(0,len(pr_threshods)):\n",
        "\n",
        "           if (precision1[k]+precision1[k])>0:\n",
        "              all_F_measure[k]=2*precision1[k]*recall[k]/(precision1[k]+recall[k])\n",
        "           else:\n",
        "              all_F_measure[k]=0\n",
        "\n",
        "        max_index=all_F_measure.argmax()\n",
        "        predicted_score=np.zeros(len(real_labels))\n",
        "        threshold=pr_threshods[max_index]\n",
        "        p=ae_y_pred_prob[:,1]\n",
        "        predicted_score[p>threshold]=1\n",
        "        f=f1_score(real_labels,predicted_score)\n",
        "        recall=recall_score(real_labels, predicted_score)\n",
        "        precision1=precision_score(real_labels, predicted_score)\n",
        "        print(\"RAW DNN:\",recall, precision1,'auc:', auc_score,'aupr', aupr_score,f)\n",
        "        all_performance_DNN.append([recall,precision1,auc_score,aupr_score,f])\n",
        "    print('recall,precision,auc_score,aupr_score,fscore')\n",
        "    print(np.mean(np.array(all_performance_DNN), axis=0))\n",
        "\n",
        "DeepMDA()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "adxi9yF59VQj",
        "outputId": "b59651f7-e5d7-4eda-8dae-e2c1964c8be4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2403/2403 [==============================] - 8s 2ms/step - loss: 0.5949\n",
            "Epoch 2/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.5127\n",
            "Epoch 3/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.5055\n",
            "Epoch 4/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.5030\n",
            "Epoch 5/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.5013\n",
            "Epoch 6/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.5004\n",
            "Epoch 7/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.5000\n",
            "Epoch 8/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4989\n",
            "Epoch 9/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4994\n",
            "Epoch 10/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4983\n",
            "Epoch 11/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4983\n",
            "Epoch 12/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4976\n",
            "Epoch 13/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4978\n",
            "Epoch 14/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4979\n",
            "Epoch 15/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4975\n",
            "Epoch 16/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4972\n",
            "Epoch 17/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4968\n",
            "Epoch 18/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4968\n",
            "Epoch 19/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4967\n",
            "Epoch 20/20\n",
            "2403/2403 [==============================] - 5s 2ms/step - loss: 0.4967\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9f65514f096c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_performance_DNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m \u001b[0mDeepMDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-9f65514f096c>\u001b[0m in \u001b[0;36mDeepMDA\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mmodel_DNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label_new_forDNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_DNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mae_y_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_DNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMCC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_performace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
          ]
        }
      ]
    }
  ]
}